{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib widget\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv(\"train.csv\")\n",
    "testdata = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = traindata.pop(\"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in traindata.columns:\n",
    "    if traindata[col].dtype ==\"object\":\n",
    "        traindata[col]=traindata[col].fillna(\"None\")\n",
    "        testdata[col] = testdata[col].fillna(\"None\")\n",
    "    if traindata[col].dtype in [\"float64\",\"int64\"] :\n",
    "        traindata[col]=traindata[col].fillna(0.0)\n",
    "        testdata[col]=testdata[col].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = traindata.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [col for col in traindata.columns if traindata[col].dtype==\"object\"]:\n",
    "    tokenizer = Tokenizer(num_words=len(pd.unique(traindata[col])),lower=False)\n",
    "    tokenizer.fit_on_texts(traindata[col])\n",
    "    traindata[col] = pd.DataFrame(tokenizer.texts_to_sequences(traindata[col]))\n",
    "    testdata[col] = pd.DataFrame(tokenizer.texts_to_sequences(testdata[col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1\n",
       "1          2\n",
       "2          3\n",
       "3          4\n",
       "4          5\n",
       "        ... \n",
       "1455    1456\n",
       "1456    1457\n",
       "1457    1458\n",
       "1458    1459\n",
       "1459    1460\n",
       "Name: Id, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.pop(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecttrain = pd.DataFrame([traindata.LotFrontage,traindata.LotArea,traindata.YrSold]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(79,name=\"input\"),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(1,name=\"output\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.mean_squared_logarithmic_error,optimizer='sgd',metrics = [tf.keras.metrics.MeanAbsolutePercentageError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1182 - mean_absolute_percentage_error: 27.6351\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1180 - mean_absolute_percentage_error: 27.6703\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1178 - mean_absolute_percentage_error: 27.6200\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1176 - mean_absolute_percentage_error: 27.6199\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1174 - mean_absolute_percentage_error: 27.4889\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1172 - mean_absolute_percentage_error: 27.5143\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1170 - mean_absolute_percentage_error: 27.5053\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1168 - mean_absolute_percentage_error: 27.4761\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1166 - mean_absolute_percentage_error: 27.4448\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.1164 - mean_absolute_percentage_error: 27.3718\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1163 - mean_absolute_percentage_error: 27.3686\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1161 - mean_absolute_percentage_error: 27.3918\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1159 - mean_absolute_percentage_error: 27.3351\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1157 - mean_absolute_percentage_error: 27.2767\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1155 - mean_absolute_percentage_error: 27.1926\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.1153 - mean_absolute_percentage_error: 27.2073\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1151 - mean_absolute_percentage_error: 27.2467\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1150 - mean_absolute_percentage_error: 27.2157\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1148 - mean_absolute_percentage_error: 27.1588\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1146 - mean_absolute_percentage_error: 27.1533\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1144 - mean_absolute_percentage_error: 27.0793\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1142 - mean_absolute_percentage_error: 27.0673\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1140 - mean_absolute_percentage_error: 27.0423\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1139 - mean_absolute_percentage_error: 26.9870\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1137 - mean_absolute_percentage_error: 27.0521\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1135 - mean_absolute_percentage_error: 26.9920\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1134 - mean_absolute_percentage_error: 26.9389\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1132 - mean_absolute_percentage_error: 26.9015\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1130 - mean_absolute_percentage_error: 26.9016\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1128 - mean_absolute_percentage_error: 26.8858\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1127 - mean_absolute_percentage_error: 26.8449\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1125 - mean_absolute_percentage_error: 26.8432\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1123 - mean_absolute_percentage_error: 26.8294\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1122 - mean_absolute_percentage_error: 26.7653\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1120 - mean_absolute_percentage_error: 26.7357\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1118 - mean_absolute_percentage_error: 26.7396\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.1117 - mean_absolute_percentage_error: 26.7559\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1115 - mean_absolute_percentage_error: 26.6634\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1113 - mean_absolute_percentage_error: 26.6615\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1112 - mean_absolute_percentage_error: 26.6286\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1110 - mean_absolute_percentage_error: 26.6136\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1108 - mean_absolute_percentage_error: 26.6293\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.1107 - mean_absolute_percentage_error: 26.5719\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1105 - mean_absolute_percentage_error: 26.5035\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.1104 - mean_absolute_percentage_error: 26.4925\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1102 - mean_absolute_percentage_error: 26.4926\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1100 - mean_absolute_percentage_error: 26.4645\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1099 - mean_absolute_percentage_error: 26.4924\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1097 - mean_absolute_percentage_error: 26.4625\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1096 - mean_absolute_percentage_error: 26.4133\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1094 - mean_absolute_percentage_error: 26.4274\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1093 - mean_absolute_percentage_error: 26.3298\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1091 - mean_absolute_percentage_error: 26.3686\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1090 - mean_absolute_percentage_error: 26.3321\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1088 - mean_absolute_percentage_error: 26.3624\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1087 - mean_absolute_percentage_error: 26.2833\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1085 - mean_absolute_percentage_error: 26.2358\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1083 - mean_absolute_percentage_error: 26.2500\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1082 - mean_absolute_percentage_error: 26.2254\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1080 - mean_absolute_percentage_error: 26.1862\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1079 - mean_absolute_percentage_error: 26.1370\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1078 - mean_absolute_percentage_error: 26.0947\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1076 - mean_absolute_percentage_error: 26.1410\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1075 - mean_absolute_percentage_error: 26.0872\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1073 - mean_absolute_percentage_error: 26.0758\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1072 - mean_absolute_percentage_error: 26.0596\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1070 - mean_absolute_percentage_error: 26.0870\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1069 - mean_absolute_percentage_error: 25.9858\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1067 - mean_absolute_percentage_error: 25.9591\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 965us/step - loss: 0.1066 - mean_absolute_percentage_error: 25.9005\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 951us/step - loss: 0.1064 - mean_absolute_percentage_error: 25.9401\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1063 - mean_absolute_percentage_error: 25.9271\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1062 - mean_absolute_percentage_error: 25.8945\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 986us/step - loss: 0.1060 - mean_absolute_percentage_error: 25.9384\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1059 - mean_absolute_percentage_error: 25.8904\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1057 - mean_absolute_percentage_error: 25.8360\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1056 - mean_absolute_percentage_error: 25.8116\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 901us/step - loss: 0.1055 - mean_absolute_percentage_error: 25.8104\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1053 - mean_absolute_percentage_error: 25.7750\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1052 - mean_absolute_percentage_error: 25.7564\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1051 - mean_absolute_percentage_error: 25.7170\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1049 - mean_absolute_percentage_error: 25.7595\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 819us/step - loss: 0.1048 - mean_absolute_percentage_error: 25.7009\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 961us/step - loss: 0.1047 - mean_absolute_percentage_error: 25.6384\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.1045 - mean_absolute_percentage_error: 25.6821\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 824us/step - loss: 0.1044 - mean_absolute_percentage_error: 25.6020\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1043 - mean_absolute_percentage_error: 25.6111\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1041 - mean_absolute_percentage_error: 25.6012\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1040 - mean_absolute_percentage_error: 25.5930\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 955us/step - loss: 0.1039 - mean_absolute_percentage_error: 25.5552\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 861us/step - loss: 0.1037 - mean_absolute_percentage_error: 25.5634\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 838us/step - loss: 0.1036 - mean_absolute_percentage_error: 25.4989\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1035 - mean_absolute_percentage_error: 25.5378\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1034 - mean_absolute_percentage_error: 25.4611\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 958us/step - loss: 0.1033 - mean_absolute_percentage_error: 25.4918\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1031 - mean_absolute_percentage_error: 25.4648\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 894us/step - loss: 0.1030 - mean_absolute_percentage_error: 25.4354\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 751us/step - loss: 0.1029 - mean_absolute_percentage_error: 25.4152\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 766us/step - loss: 0.1027 - mean_absolute_percentage_error: 25.4158\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 753us/step - loss: 0.1026 - mean_absolute_percentage_error: 25.3520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce92902a90>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=traindata,y=trainLabels,epochs=100,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[156152.66]\n",
      " [164589.75]\n",
      " [180401.6 ]\n",
      " [163823.06]\n",
      " [212480.92]]\n",
      "0    208500\n",
      "1    181500\n",
      "2    223500\n",
      "3    140000\n",
      "4    250000\n",
      "Name: SalePrice, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(traindata.head()))\n",
    "print(trainLabels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.012052532285451889"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(traindata,trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = testdata.pop(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(model.predict(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Id\"] = Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns = [\"SalePrice\",\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>125722.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>249647.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>171913.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>191702.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>186241.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>90683.929688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>90265.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>173667.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>94221.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>248825.281250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SalePrice\n",
       "Id                 \n",
       "1461  125722.453125\n",
       "1462  249647.546875\n",
       "1463  171913.265625\n",
       "1464  191702.500000\n",
       "1465  186241.453125\n",
       "...             ...\n",
       "2915   90683.929688\n",
       "2916   90265.000000\n",
       "2917  173667.781250\n",
       "2918   94221.773438\n",
       "2919  248825.281250\n",
       "\n",
       "[1459 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.set_index(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nan_vals = testdata.isna()\n",
    "nan_cols = nan_vals.any()\n",
    "colwnan = testdata.columns[nan_cols].to_list()\n",
    "print(colwnan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"results.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83f666f892ff76c838f7fddfd72a01fb9d448ab5c4ef1253de7c36d4b13e0fa2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
